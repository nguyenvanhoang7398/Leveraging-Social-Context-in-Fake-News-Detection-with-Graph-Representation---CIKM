Camera-ready (17/08/2020):

Reviewer #1:
1. It is claimed at Abstract that FANG is efficient at inference time, but there is nowhere in the paper about the discussion of inference time.

> Hoang: Agree, added the Section 5.4. Scalable Inductiveness

2. When digging into the two examples at Section 5.4, it is unclear why FANG pays most of its attention to a tweet by user B or user C. In other words, it would be nice to provide some solid evidences such as experiment data to illustrate.

> Hoang: I am not sure what is the good interpretation of FANG's attention to certain users. We can consider removing the Micro-analysis entirely as they contribute little to our major claim of representation learning.

3. Lastly, it would have been informative to give a clearer algorithm design introduction.

> Hoang: Added algorithm instruction in Algorithm 1.

Reviewer #2:
1. While the stance detection based on user comments are considered, external clues/evidence to disprove a claim is not considered. For example, in social networks typically social echo chambers are where the fake news spreads and those users ideologically agree with each other. However, there could be credible evidence elsewhere in news or scientific articles which is crucial for fact checking and identifying false claims made on social networks.

> Hoang: We have already discuss evidence (content)-based and context-based fake news detection in the Introduction, specifically in "Evidence-based approaches ... claims about images and videos". To avoid further confusion, I have specified the scope under "This research focuses on improving contextual fake news detection..." near the end of the Introduction section.

2. More stronger baselines could be used. CSI and GCN seems to be in a disadvantage because they do not have access to all the features

> Hoang: Ignoring this point. CSI and GCN hves access to all the features.

3. When GraphSage was used for training, does it respect the direction of the edges? especially with user follow relationship in Twitter it is often unidirectional.

> Hoang: Ignoring this point. We have already stated in Table 3 that all of our interactions are undirected.

4. Another issue is there should be some ablation study. In practice it is hard to expect availability of all the features used in the paper. It would be useful to know how robust is the model when some of the features such as user interaction or stance information are missing.

> Hoang: In addition to the temporality-abalated models presented in the submitted script, I have added the stance-ablated models in the camera-ready.

Reviewer #3:

1. The stance-annotated dataset is not well distributed between the train and test sets for the News.

> Hoang: In this task we mainly concern about the number of samples rather than the number of news. To avoid this confusion, I have removed the News column

2. Related work can be improved by considering more of recent-works, especially for the GNN part. Also, the Popat references [30] and [31] are listed in the table but not discussed in the related work.

> Hoang: I have surveyed additional recent GNN works and discussed the 2 mentioned referrences.

3. There is a gap of 10% in the total attention from FANG for the real news.

> Hoang: I have updated the attention plots.

4. The language of the paper can be enhanced by removing some typos and improve the sentence to make it more transparent. Also, there are some typos (below are the ones I catch):
Page 1 textiti.e.
Page 2 a Euclidean transformation
Page 3 as well as its of its underlying
Page 4 inn order
Page 5, Table 4 has a repeated row.
Page 8, ?? appears instead of the figure number.
